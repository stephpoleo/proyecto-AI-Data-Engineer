# üöÄ Gu√≠a de Ejecuci√≥n - AI Data Engineer Project

## üìã Prerrequisitos

### Requisitos del Sistema (Seg√∫n Especificaciones del Proyecto)
- **Sistema Operativo**: 
  - **Ubuntu 24.04** (WSL o nativo) - **REQUERIDO** para Hive/Hadoop
  - **Windows 10/11** - Solo para pruebas con c√°mara integrada
- **Python**: **3.10** (espec√≠ficamente, seg√∫n gu√≠a de instalaci√≥n del curso)
- **Memoria RAM**: M√≠nimo 8GB (recomendado 16GB)
- **Espacio en Disco**: M√≠nimo 5GB libres
- **GPU NVIDIA**: Opcional (para aceleraci√≥n CUDA)

### Infraestructura Big Data
- **Apache Hadoop**: Cluster funcionando con HDFS
- **Apache Hive**: Servidor HiveServer2 activo en puerto 10000
- **Conexi√≥n a red**: Acceso al cluster Hadoop/Hive

### Hardware Opcional
- **C√°mara web**: Para detecci√≥n en tiempo real
- **GPU NVIDIA**: Para aceleraci√≥n (CUDA opcional)

---

## ‚öôÔ∏è Instalaci√≥n y Configuraci√≥n

> **‚ö†Ô∏è IMPORTANTE - Consideraciones de Sistema Operativo:**
> 
> Este proyecto fue desarrollado siguiendo las especificaciones del **Proyecto Final del Curso "Procesos ETL para Cargas de Trabajo de IA"** y tiene requerimientos espec√≠ficos de SO:
>
> - **Para funcionamiento completo con Hive/Hadoop**: Usar **WSL (Ubuntu 24.04)** o **Linux nativo**
> - **Para detecci√≥n con c√°mara en vivo**: Usar **Windows nativo** (WSL no detecta c√°maras)
> - **Recomendaci√≥n**: Desarrollar en WSL y probar c√°mara en Windows cuando sea necesario

### 1. Clonar el Repositorio
```bash
git clone https://github.com/stephpoleo/proyecto-AI-Data-Engineer.git
cd proyecto-AI-Data-Engineer
```

### 2. Configurar Entorno Virtual y Dependencias
```bash
# Crear entorno virtual (si no existe)
make venv

# Instalar todas las dependencias
make install

# Activar entorno virtual manualmente (opcional)
source venv/bin/activate
```

### 3. Verificar Instalaci√≥n
```bash
# Ejecutar pipeline completo de desarrollo
make all
```

Este comando ejecutar√°:
- ‚úÖ Instalaci√≥n de dependencias
- ‚úÖ Formateo de c√≥digo con Black
- ‚úÖ Linting con Pylint  
- ‚úÖ Ejecuci√≥n de pruebas unitarias

Para aclarar dudas sobre los comandos del Make hacer:
```bash
make help
```
---

## üîß Configuraci√≥n Inicial

### 1. Configurar Conexi√≥n a Hive

Editar el archivo `src/etl/warehouse.py`:

```python
HIVE_CONN_ARGS = dict(
    host="localhost",        # Cambiar por IP del servidor Hive
    port=10000,             # Puerto HiveServer2
    username="tu_usuario",   # Tu usuario
    database="yolo_db",     # Base de datos (se crea autom√°ticamente)
    auth="NONE",            # M√©todo de autenticaci√≥n
)
```

### 2. Configurar C√°mara (Solo para Modo Live)

> **üö® LIMITACI√ìN CR√çTICA DE WSL:**
> 
> **WSL NO DETECTA C√ÅMARAS USB NI INTEGRADAS**. Para usar el modo `live_camera`:
> 
> 1. **Cambiar a Windows nativo** temporalmente
> 2. **Instalar Python 3.10** en Windows
> 3. **Instalar dependencias** con `pip install -r requirements.txt`
> 4. **Ejecutar solo el modo c√°mara** en Windows
> 5. **Procesar los CSV generados** de vuelta en WSL con Hive

**Diagn√≥stico de c√°maras (solo en Windows):**
```bash
python test_camera.py
```

**Configuraci√≥n manual de c√°mara:**
```python
# En src/vision/config.py
CAM_INDEX = 0  # Generalmente 0 para c√°mara integrada
```

### 3. Preparar Datos de Entrada (Requisitos del Proyecto)

> **üìã REQUERIMIENTOS ESPEC√çFICOS DEL PROYECTO FINAL:**

#### Para Im√°genes (OBLIGATORIO):
```bash
# Crear directorio y agregar im√°genes
mkdir -p data/input/images
# Formatos: .jpg, .png, .bmp, etc.
```

#### Para Videos (OBLIGATORIO):
```bash
# Crear directorio y agregar videos  
mkdir -p data/input/videos
# Formatos: .mp4, .avi, .mov, etc.
```

#### Para C√°mara en Vivo (OPCIONAL):
```bash
# No requiere archivos de entrada
```

---

## üéØ Modos de Ejecuci√≥n

> **üìù CONFIGURACI√ìN DE MODO DE AN√ÅLISIS:**
>
> **Para cambiar el tipo de an√°lisis**, editar `main.py`:
> ```python
> program_mode = ["live_camera", "image", "video"]  
> run_classification_system(program_mode[X])  # Cambiar X por:
> # X = 0 ‚Üí C√°mara en vivo (solo Windows)
> # X = 1 ‚Üí Procesamiento de im√°genes (WSL/Linux)  
> # X = 2 ‚Üí Procesamiento de videos (WSL/Linux)
> ```

### M√©todo 1: Ejecuci√≥n Completa (Recomendado para WSL/Linux)

```bash
# Ejecutar sistema completo: Clasificaci√≥n + ETL
python main.py
```

**¬øQu√© hace este comando?**
1. üîç Ejecuta detecci√≥n YOLO seg√∫n modo configurado en main.py
2. üíæ Guarda detecciones en CSV (`data/output/detections_YYYYMMDD_HHMMSS.csv`)
3. üîÑ Procesa CSV con pipeline ETL (Extract ‚Üí Transform ‚Üí Load)
4. üèõÔ∏è Carga datos limpios a Hive **SIN DUPLICADOS**
5. üìä Ejecuta 5 consultas anal√≠ticas autom√°ticamente

### M√©todo 2: Ejecuci√≥n por M√≥dulos

#### Solo Sistema de Clasificaci√≥n:
```python
from src.vision.classification_system import run_classification_system

# Opciones de modo:
run_classification_system("live_camera")  # C√°mara en vivo
run_classification_system("image")        # Procesar im√°genes  
run_classification_system("video")        # Procesar videos
```

#### Solo Sistema ETL:
```python
from src.etl.batch_etl_system import run_batch_etl_system

run_batch_etl_system()  # Procesa CSV existentes
```

---

## üéÆ Modos de Clasificaci√≥n Disponibles

### üì∑ Modo 0: C√°mara en Vivo ‚ö†Ô∏è (Solo Windows)
```python
# En main.py cambiar:
program_mode = ["live_camera", "image", "video"]  
run_classification_system(program_mode[0])  # √çndice 0 = c√°mara
```

**üö® IMPORTANTE**: Este modo **SOLO FUNCIONA EN WINDOWS** debido a limitaciones de WSL con hardware de c√°mara.

**Workflow recomendado:**
1. **Ejecutar en Windows**: Generar CSV con detecciones de c√°mara
2. **Transferir CSV a WSL**: Copiar archivos a `data/output/`
3. **Procesar en WSL**: Ejecutar solo el sistema ETL

**Controles:**
- `q`: Salir de la previsualizaci√≥n
- `Ctrl+C`: Terminar procesamiento sin preview

### üñºÔ∏è Modo 1: Procesamiento de Im√°genes (WSL/Linux Compatible)
```python
# En main.py cambiar:
run_classification_system(program_mode[1])  # √çndice 1 = im√°genes (DEFAULT)
```

**Comportamiento:**
- Procesa **im√°genes guardadas por el usuario** en `data/input/images/`
- Muestra preview de cada detecci√≥n con bounding boxes
- Presiona `q` para continuar a la siguiente imagen

### üé¨ Modo 2: Procesamiento de Videos (WSL/Linux Compatible)
```python  
# En main.py cambiar:
run_classification_system(program_mode[2])  # √çndice 2 = videos
```

**Comportamiento:**
- Procesa **videos guardados por el usuario** en `data/input/videos/`
- **Requisitos del proyecto**: Videos deben tener una duraci√≥n m√°x. 20 seg o 50MB
- Detecci√≥n frame por frame con an√°lisis temporal
- **Lotes de 10 segundos**: El sistema ETL env√≠a datos cada 10 segundos de contenido
- Preview en tiempo real del procesamiento
- Presiona `q` para saltar al siguiente video

---

## üìä Monitoreo y Resultados

### Archivos Generados

#### CSV de Detecciones (Staging)
```bash
data/output/detections_20251118_143052.csv
```

### Consultas Anal√≠ticas Autom√°ticas

El sistema ejecuta autom√°ticamente 5 consultas despu√©s de cada carga:

1. **üìà Objetos por Clase**
```sql
SELECT class_name, COUNT(*) as total_detections 
FROM yolo_objects 
GROUP BY class_name 
ORDER BY total_detections DESC;
```

2. **üë• Personas por Video**
```sql
SELECT source_id, COUNT(*) as person_count 
FROM yolo_objects 
WHERE class_name = 'person' 
GROUP BY source_id;
```

3. **üìè √Årea Promedio por Clase**
```sql
SELECT class_name, AVG(area_pixels) as avg_area
FROM yolo_objects 
GROUP BY class_name;
```

4. **üé® Distribuci√≥n de Colores**
```sql
SELECT class_name, dominant_color_name, COUNT(*) as color_count
FROM yolo_objects 
GROUP BY class_name, dominant_color_name;
```

5. **‚è∞ Objetos por Ventana Temporal**
```sql
SELECT time_window_10s, COUNT(*) as objects_in_window
FROM yolo_objects 
GROUP BY time_window_10s 
ORDER BY time_window_10s;
```

---

## üîß Soluci√≥n de Problemas Comunes

### üö® Error: "Could not open camera with index 0"

**Causa Principal:** Est√°s ejecutando en WSL (¬°WSL no soporta c√°maras!)

**Soluci√≥n WSL ‚Üí Windows:**
```bash
# 1. Cambiar a Windows nativo
# 2. Instalar Python 3.10 en Windows
# 3. Instalar dependencias: pip install -r requirements.txt
# 4. Ejecutar: python main.py (con program_mode[0])
# 5. Transferir CSV generados de vuelta a WSL para procesamiento ETL
```

**Soluci√≥n en Windows nativo:**
```bash
# 1. Diagnosticar c√°maras disponibles
python test_camera.py

# 2. Verificar que la c√°mara no est√© en uso por otra aplicaci√≥n
# 3. Probar diferentes √≠ndices de c√°mara (0, 1, 2...)
# 4. Reiniciar si es necesario
```

**Soluci√≥n Linux nativo:**
```bash
# 1. Diagnosticar c√°maras disponibles
python test_camera.py

# 2. Agregar usuario al grupo video
sudo usermod -a -G video $USER

# 3. Reiniciar sesi√≥n o reiniciar sistema

# 4. Verificar dispositivos
ls /dev/video*

# 5. Instalar herramientas v4l (si es necesario)
sudo apt install v4l-utils
```

### üö® Error: "Could not connect to Hive"

**Causa:** Servidor Hive no est√° corriendo o configuraci√≥n incorrecta

**Soluci√≥n:**
```bash
# 1. Verificar que HiveServer2 est√© corriendo
jps | grep HiveServer2

# 2. Verificar puerto
netstat -tlnp | grep 10000

# 3. Probar conexi√≥n manual
beeline -u "jdbc:hive2://localhost:10000" -n tu_usuario

# 4. Revisar configuraci√≥n en warehouse.py
```

### üö® Error: "No module named 'pyhive'"

**Causa:** Dependencias no instaladas correctamente

**Soluci√≥n:**
```bash
# Reinstalar entorno
rm -rf venv/
make install

# O instalar manualmente
source venv/bin/activate
pip install -r requirements.txt
```

### üö® Error: "No images/videos found"

**Causa:** Directorios de entrada vac√≠os

**Soluci√≥n:**
```bash
# Verificar estructura de directorios
tree data/

# Agregar archivos de muestra
cp /ruta/a/tus/imagenes/* data/input/images/
cp /ruta/a/tus/videos/* data/input/videos/
```

---

## üìù Comandos de Desarrollo

### Formateo y Linting
```bash
# Formatear c√≥digo autom√°ticamente
make format

# An√°lisis de c√≥digo (linting)  
make lint

# Ejecutar pruebas
make test
```

### Limpieza de Datos
```python
# Limpiar tabla Hive (¬°CUIDADO: Borra todos los datos!)
from src.etl.warehouse import clear_yolo_table
clear_yolo_table(debug=True)
```

### An√°lisis Manual
```python
# Ejecutar solo consultas anal√≠ticas
from src.etl.warehouse import run_hive_analytics
resultados = run_hive_analytics(debug=True, print_results=True)
```

---

## üÜò Soporte y Recursos

### üìñ Documentaci√≥n de Referencia del Proyecto
Este proyecto implementa las especificaciones del **"Proyecto Final ‚Äì Deep Learning, Visi√≥n por Computador y Big Data (YOLO + Hive)"** del curso "Procesos ETL para Cargas de Trabajo de IA".

**Documentaci√≥n completa disponible en:**
```bash
Documentacion clases/finalproject/ProyectoEnEspanol.md
```

### üîß Workflows Espec√≠ficos por Sistema Operativo

#### **Workflow WSL (Desarrollo Principal):**
```bash
1. Desarrollar y probar en WSL Ubuntu 24.04
2. Usar modo image (program_mode[1]) o video (program_mode[2])
3. Procesar con sistema ETL completo hacia Hive
4. Ejecutar consultas anal√≠ticas autom√°ticas
```

#### **Workflow Windows (Solo para C√°mara):**
```bash
1. Cambiar program_mode a [0] en main.py
2. Ejecutar python main.py en Windows nativo
3. Transferir CSV generados a WSL
4. Procesar CSV en WSL con sistema ETL
```

### Archivos de Referencia del Curso
```bash
# El proyecto incluye ejemplos y gu√≠as en:
Documentacion clases/sesion_5_y_6/procesosbatch/
Documentacion clases/sesion_5_y_6/guias/
Documentacion clases/finalproject/
```

---

## ‚úÖ Lista de Verificaci√≥n Pre-Ejecuci√≥n

### Requisitos Obligatorios del Proyecto Final:
- [ ] **Ubuntu 24.04** (WSL o nativo) funcionando
- [ ] **Python 3.10** espec√≠ficamente instalado
- [ ] **Apache Hadoop** instalado y HDFS funcionando
- [ ] **Apache Hive** instalado y HiveServer2 activo (puerto 10000)
- [ ] **Entorno virtual** creado (`make venv`)
- [ ] **Dependencias instaladas** (`make install`)
- [ ] **Configuraci√≥n Hive** actualizada en `warehouse.py`
- [ ] **Modo de ejecuci√≥n** configurado en `main.py` (`program_mode[X]`)

### Verificaciones T√©cnicas:
- [ ] **Makefile funcional** (linting, formato, pruebas)
- [ ] **Carpeta tests/** con pruebas unitarias
- [ ] **Espacio en disco suficiente** (>5GB recomendado)
- [ ] **Conectividad de red** al cluster Hadoop/Hive

---

## üéâ ¬°Listo para Ejecutar!

### Configuraci√≥n Final del Modo:
```python
# PASO CR√çTICO: Editar main.py antes de ejecutar
program_mode = ["live_camera", "image", "video"]  
run_classification_system(program_mode[1])  # Cambiar √≠ndice:
# 0 = live_camera (solo Windows)
# 1 = image (WSL/Linux) ‚Üê RECOMENDADO PARA PRIMER USO
# 2 = video (WSL/Linux)
```

### Ejecuci√≥n Principal:
```bash
# En WSL/Linux (modo recomendado)
python main.py

# Esperar a ver (seg√∫n especificaciones del proyecto):
# ‚úÖ Sistema de clasificaci√≥n ejecutado (YOLO + atributos)
# ‚úÖ CSV generado en data/output/ (capa de staging)
# ‚úÖ Sistema ETL iniciado (Extract ‚Üí Transform ‚Üí Load)
# ‚úÖ Datos cargados a Hive SIN DUPLICADOS (requisito imperativo)
# ‚úÖ 5 consultas anal√≠ticas ejecutadas autom√°ticamente
# ‚úÖ Lotes de 10 segundos procesados (para videos)
```

### Resultado Esperado:
```bash
===============================================================================
RESULTADOS: Objects per class
===============================================================================
   class_name  total_detections
0      person               45  
1         car               23
2      laptop               12
...

===============================================================================
RESULTADOS: People per video  
===============================================================================
     source_id  person_count
0    video1.mp4           8
1    video2.mp4           12
```

### üéØ **Validaci√≥n de Cumplimiento:**
- ‚úÖ **Dos sistemas separados**: Clasificaci√≥n + ETL independientes
- ‚úÖ **Extracci√≥n rica de atributos**: 25+ campos por detecci√≥n
- ‚úÖ **Prevenci√≥n de duplicados**: L√≥gica de sincronizaci√≥n implementada  
- ‚úÖ **Lotes de 10 segundos**: Para videos seg√∫n especificaci√≥n
- ‚úÖ **Consultas anal√≠ticas**: 5 consultas autom√°ticas en Hive
- ‚úÖ **Buenas pr√°cticas**: Makefile, tests, linting, documentaci√≥n
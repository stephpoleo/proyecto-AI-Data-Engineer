# Repo AI Data Engineer

Information about the course `Curso Procesos ETL para Workloads de AI` part of the `Programa Certified AI Data Engineer`

## To All Students

T# Final Project – Deep Learning, Computer Vision and Big Data (YOLO + Hive)

## 1. Overview

This project integrates **Deep Learning**, **Computer Vision**, and **Big Data Processing**.  
Each student will build an end-to-end solution composed of **two clearly separated systems**:

1. A **Classification System**:
   - Runs YOLO (or another neural network) over images and videos.
   - Extracts rich attributes for every detected object.
   - Writes all detections **locally into CSV files** (staging area).

2. A **Batch / ETL System** (Python only, no PySpark):
   - Reads the CSV files generated by the Classification System.
   - Performs **extraction, cleaning, transformation and loading (ETL)**.
   - Sends the processed data in batches to **Apache Hive**, following specific time rules (for video) and completion rules (for images).
   - Ensures **no duplicated data** is ever loaded into Hive.

The entire solution must follow good engineering practices: virtual environment, Makefile, linting, formatting, tests and documentation.

---

## 2. Operating System and Python Requirements

1. **Ubuntu 24.04**
2. **Python 3.10**  
   - Must be installed following:  
     `sesion_5_y_6/guias/Guia_Instalacion_Python310_OpenCV_v410.pdf`
3. **Apache HDFS** installed and running
4. **Apache Hive** installed and running
5. **NVIDIA GPU (optional)**  
   - If your computer has an NVIDIA GPU, you must install:
     - OpenCV with CUDA
     - TensorFlow with CUDA  
   - Refer to:  
     `sesion_5_y_6/StepByStepToInstallOpenCVWithCudaSupport.txt`

---

## 3. Python Virtual Environment Requirements

You must create **the entire project inside a Python virtual environment**.

### Mandatory requirements:

1. Use a **Makefile** to automate:
   - Creation of the virtual environment
   - Installation of dependencies
   - Linting (pylint)
   - Formatting (black or autopep8)
   - Running unit tests
2. Provide a **requirements.txt** file with all dependencies.
3. Include a **tests/** folder with tests for every `.py` and `.ipynb` file.
4. Every `.py` and `.ipynb` file must be **well documented**, with:
   - Function docstrings
   - Comments explaining logic blocks
   - Clear explanation of the main pipeline steps

---

## 4. Project Requirements

### 4.1 Data Requirements

1. Minimum **20 different images**.
2. Minimum **2 videos**:
   - Each must contain people.
   - Maximum 20 seconds long OR maximum 50 MB each.
3. Images/videos **must be captured by you** (do not download from the internet).
4. For **real-time capture**, you may use:
   - USB camera
   - CSI camera
   - RTSP camera  
   You must inform the instructor which camera type you will use.

### 4.2 Model Requirements

1. You may use:
   - Pretrained YOLO model
   - Fine-tuned pretrained model
   - Your own custom neural network
2. You may use **one or multiple neural networks**.
3. The main purpose is **object classification and enriched attribute extraction**.

---

## 5. Detection Requirements

Your solution **must**:

1. Detect at least **15 different objects/features** in your images.
2. Detect at least **10 different objects/features** in your videos.
3. For **each detected object**, extract as much information as possible (see Section 6).

---

## 6. Object Attributes to Extract

For **every detected object**, you must extract and store at least the following:

### A. Raw YOLO Output

- `source_type` – `"image"` or `"video"`
- `source_id` – file name (e.g. `image_01.jpg`, `video_01.mp4`)
- `frame_number` – 0 for images, frame index for video
- `class_id`
- `class_name`
- `confidence`

### B. Bounding Box Information

- `x_min`, `y_min`, `x_max`, `y_max`
- `width`, `height`
- `area_pixels` = `width * height`
- `frame_width`, `frame_height`
- `bbox_area_ratio` = `area_pixels / (frame_width * frame_height)`
- `center_x`, `center_y`
- `center_x_norm`, `center_y_norm` (normalized 0–1)
- `position_region` – one of:
  - `top-left`, `top-center`, `top-right`
  - `middle-left`, `middle-center`, `middle-right`
  - `bottom-left`, `bottom-center`, `bottom-right`

### C. Dominant Color (Computed with OpenCV)

From the object ROI:

- `dominant_color_name` – e.g. `red`, `green`, `blue`, `black`, `white`, `yellow`, etc.
- `dom_r`, `dom_g`, `dom_b` – dominant RGB components

### D. Video Metadata (If Applicable)

- `timestamp_sec` – approximate time of the frame (e.g. `frame_number / fps`)

### E. Optional Person-Related Features

If `class_name == "person"`, you may additionally include:

- Boolean flags for overlapping objects (`has_backpack`, `has_cellphone`, etc.)
- Number of nearby objects in the same frame
- Pose estimation outputs (optional)
- Emotion classification (optional)

---

## 7. Two-System Architecture (Mandatory Separation)

Your project **must be implemented as two different systems / Python entry points**:

### 7.1 Classification System

- Implemented in one or more Python files (e.g. `classification_system.py`).
- Responsibilities:
  - Load YOLO (and any auxiliary models).
  - Process images and videos.
  - Extract all attributes described in Section 6.
  - **Write all detections locally into one or more CSV files** (this is the staging layer).
- Constraints:
  - This system **must NOT** connect to Hive directly.
  - It is responsible only for **detection and local CSV output**.

Recommended CSV fields (one row per detected object):

- All fields from Section 6 plus:
  - `ingestion_date` – date/time when the detection was generated.
  - A **unique identifier** (e.g. `detection_id` or composite key `source_id + frame_number + local_object_id`).

### 7.2 Batch / ETL System (Python Only)

- Implemented in a separate Python file (e.g. `batch_etl_system.py`).
- **No PySpark allowed**: use **pure Python** (e.g. `csv`, `pandas`, and a Hive connector or CLI).
- Responsibilities:
  1. **Extraction**:  
     - Read the CSV files generated by the Classification System.
  2. **Cleaning**:  
     - Handle missing values, invalid coordinates, invalid confidences, etc.
  3. **Transformation**:  
     - Normalize and cast types.
     - Generate derived fields if needed.
  4. **Loading into Hive**:  
     - Insert the records into a Hive table **without duplicates**.

#### Batch Sending Rules

- For **images**:
  - Once the analysis of all images is complete, the ETL system must send the corresponding detections to Hive.
- For **videos**:
  - The ETL system must send the detections in **time windows of 10 seconds of video content**.
  - Example:
    - For a 40-second video, there will be up to 4 logical batches:  
      `[0–10s], [10–20s], [20–30s], [30–40s]`.

You may implement the 10-second grouping based on `timestamp_sec` or `frame_number` and `fps`.

#### No Duplicate Data (Imperative Requirement)

- **It is strictly forbidden to send duplicate detections to Hive.**
- You must design a **synchronization strategy** between the two systems so that:

  - Each detection is loaded **only once**.
  - Re-running the ETL system does **not** create additional copies of the same detection.

Examples of strategies (you can choose one and document it):

- Use a **unique key** (e.g. `source_id`, `frame_number`, `class_id`, `local_object_id`) and:
  - Deduplicate in Python before loading.
  - Or define a constraint / logic in Hive that avoids inserting existing keys.
- Maintain a local **checkpoint file** or a processed flag to track which CSV rows have already been sent.

---

## 8. Output Dataset and Hive Schema

You must produce structured data (from the Batch / ETL System) and load it into Hive as:

- **CSV** or **Parquet** files in HDFS, and
- One or more **Hive tables**.

Example Hive table schema (you can adapt it):

```sql
CREATE EXTERNAL TABLE yolo_objects (
  source_type           STRING,
  source_id             STRING,
  frame_number          INT,
  class_id              INT,
  class_name            STRING,
  confidence            DOUBLE,
  x_min                 INT,
  y_min                 INT,
  x_max                 INT,
  y_max                 INT,
  width                 INT,
  height                INT,
  area_pixels           INT,
  frame_width           INT,
  frame_height          INT,
  bbox_area_ratio       DOUBLE,
  center_x              DOUBLE,
  center_y              DOUBLE,
  center_x_norm         DOUBLE,
  center_y_norm         DOUBLE,
  position_region       STRING,
  dominant_color_name   STRING,
  dom_r                 INT,
  dom_g                 INT,
  dom_b                 INT,
  timestamp_sec         DOUBLE,
  ingestion_date        STRING,
  detection_id          STRING
)
STORED AS PARQUET
LOCATION 'hdfs:///projects/yolo_objects/hive/';

```

## 9. Analytical Queries (Hive)

You must provide at least 5 analytical queries in Hive, for example:

1. Total number of detections per class.
2. Number of persons per video.
3. Average bounding-box area per class.
4. Distribution of dominant colors per class.
5. Number of objects per 10-second interval in each video.

## 10. Deliverables

Your submission must include:

* README.md with clear execution instructions.
* FINAL_PROJECT_GUIDE_EN.md and GUIA_PROYECTO_FINAL_ES.md (optional if the instructor includes them).
* src/ folder with:
    * Classification System (YOLO + CSV writer).
    * Batch / ETL System (CSV → Hive).
* tests/ folder with unit tests.
* Makefile
* requirements.txt
* Hive DDL scripts.
* Sample images and videos used in the project.

## 11. Evaluation Criteria

| Category                                 | Weight |
| ---------------------------------------- | ------ |
| Correct YOLO detection                   | 20%    |
| Attribute extraction quality             | 20%    |
| Local CSV logging & 2-system separation  | 15%    |
| Correct ETL logic & periodic batch rules | 20%    |
| No duplicates in Hive                    | 10%    |
| Code quality + Makefile + tests          | 10%    |
| Documentation                            | 5%     |

## 12. Notes

This is an engineering-level project.
Your work must be clean, reproducible, modular and well-documented, with a clear separation between:
* Classification System (detection + CSV)
* Batch / ETL System (CSV → Hive, no duplicates)

## Good luck!
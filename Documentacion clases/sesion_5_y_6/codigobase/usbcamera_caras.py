import cv2
import argparse
from cameradrive import streamingmultiplescamaras as cam

window_title = "Camara USB para deteccion de rostros"

"""parametros para los colores de los textos"""
color_texto_ojos = (0, 36, 255)
color_texo_caras = (139, 0, 0)
color_texto_sonrisa = (42, 42, 128)

"""parametro utilizado para la deteccion de rostros"""
color_de_la_cara = (212, 255, 127)
caras_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

"""parametros de configuracion para la deteccion de ojos"""
color_de_los_ojos = (255, 212, 0)
ojos_cascade = cv2.CascadeClassifier("haarcascade_eye.xml")

"""parametros de configuracion para la deteccion de sonrisas"""
color_sonrisa = (0, 100, 0)
sonrisa_cascade = cv2.CascadeClassifier("haarcascade_smile.xml")


def reder_frame(frame):
    """
    Procedimiento para mostar el frame la ventana de visualizacion

    Parametros:
    frame: frame del sensor
    """

    bReturn = False

    if cv2.getWindowProperty(window_title, cv2.WND_PROP_AUTOSIZE) >= 0:
        cv2.imshow(window_title, frame)
        bReturn = True
    else:
        bReturn = False

    return bReturn


def drawRect(data, color, frame):
    """
    Funcion para pintar el rectangulo por cada clasificacion:

    Parametros:
    data: datos resultado de la clasificacion
    color: color con el que se va a pintar el rectangulo
    frame: frame leido del sensor
    """

    for x, y, w, h in data:
        cv2.rectangle(frame, (x, y + 5), (x + w + 10, y + h + 20), color, 2)


def drawRectWithConfidence(
    data,
    color_rectangulo,
    frame,
    confidence=None,
    valor_filtro_confidence=0.0,
    tamano_fuente=0.9,
    grosor_fuente=1,
    color_texto=(0, 0, 0),
):
    """
    Descripcion:
    Funcion para pintar el rectangulo por cada clasificacion y adicionalmente imprime en pantalla el valor del porcentaje de efectividad en
    en la clasificacion

    Parametros:
    data: datos resultado de la clasificacion
    color: color con el que se va a pintar el rectangulo
    frame: frame leido del sensor
    confidence: valor del porcentaje de efectividad en la clasificacion
    valor_filtro_confidence: valor para realizar el filtro de la clasificacion
    tamano_fuente: valor float que me indica el tamaÃ±o de la fuente a mostrar
    grosor_fuente: valor enteo que me indica el grosor de la fuente a mostar
    color_texto: color con el que se va a imprimir el texto del confidence
    """

    drawRect(data, color_rectangulo, frame)

    if confidence is not None:
        for i, (x, y, w, h) in enumerate(data):
            if confidence[i] >= valor_filtro_confidence:
                confidence_text = f"Conf: {confidence[i]:.2f}"
                cv2.putText(
                    frame,
                    confidence_text,
                    (x, y - 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    tamano_fuente,
                    color_texto,
                    grosor_fuente,
                )


def main(
    fps,
    display_width,
    display_height,
    debug,
    enforce_fps,
    gray_scale,
    windows,
    indexcamera,
):
    # Create the Camera instance
    camera = cam(
        fps=fps,
        camera_type=3,
        device_id=indexcamera,
        to_capture_width=display_width,
        to_capture_height=display_height,
        debug=debug,
        enforce_fps=enforce_fps,
        windows=windows,
    )

    if camera.isReady():
        print("USB Camera is now ready")
        cv2.namedWindow(window_title, cv2.WINDOW_AUTOSIZE)

        while True:
            try:
                # read the camera image
                frame = camera.read()

                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

                # Convert the frame to grayscale using OpenCV
                if gray_scale:
                    frametransformado = gray
                else:
                    frametransformado = frame

                # Clasificacion de las caras
                caras, caras_rejected, caras_confidence = (
                    caras_cascade.detectMultiScale3(
                        gray,
                        scaleFactor=1.3,
                        minNeighbors=10,
                        outputRejectLevels=True,
                        flags=0,
                    )
                )

                for x, y, w, h in caras:

                    drawRectWithConfidence(
                        caras,
                        color_de_la_cara,
                        frametransformado,
                        caras_confidence,
                        3.5,
                        1.0,
                        2,
                        color_texo_caras,
                    )

                    # Asignacion de las areas de interes a analizar
                    roi_gray = gray[y : y + h, x : x + w]
                    roi_color = frametransformado[y : y + h, x : x + w]

                    # Clasificacion de los ojos
                    ojos, ojos_rejected, ojos_confidence = (
                        ojos_cascade.detectMultiScale3(
                            roi_gray,
                            scaleFactor=1.2,
                            minNeighbors=20,
                            flags=0,
                            outputRejectLevels=True,
                        )
                    )
                    drawRectWithConfidence(
                        ojos,
                        color_de_los_ojos,
                        roi_color,
                        ojos_confidence,
                        1.5,
                        0.6,
                        1,
                        color_texto_ojos,
                    )

                    sonrisa, sonrisa_rejected, sonrisa_confidence = (
                        sonrisa_cascade.detectMultiScale3(
                            roi_gray,
                            scaleFactor=1.8,
                            minNeighbors=35,
                            flags=0,
                            outputRejectLevels=True,
                        )
                    )
                    drawRectWithConfidence(
                        sonrisa,
                        color_sonrisa,
                        roi_color,
                        sonrisa_confidence,
                        2.0,
                        0.7,
                        1,
                        color_texto_sonrisa,
                    )
                    drawRectWithConfidence()

                if not reder_frame(frametransformado):
                    break

                # This also acts as
                keyCodeESC = cv2.waitKey(30) & 0xFF
                keyCodeq = cv2.waitKey(25) & 0xFF

                # Stop the program on the ESC key
                if (keyCodeESC == 27) or (keyCodeq == ord("q")):
                    break

            except KeyboardInterrupt:
                break
    else:
        print("Error opening device: ", indexcamera)

    # close the camera instance
    camera.release()

    # remove camera object
    del camera

    cv2.destroyAllWindows()


if __name__ == "__main__":

    # Initialize the argument parser
    parser = argparse.ArgumentParser(description="Arguments to setup the Camera Object")

    # Define command-line arguments
    parser.add_argument(
        "-f", "--fps", type=int, default=30, help="Frames per seconds", required=False
    )
    parser.add_argument(
        "-w",
        "--windows",
        choices=["true", "false"],
        help="Operating System",
        required=True,
    )
    parser.add_argument(
        "-ic",
        "--indexcamera",
        choices=["0", "1", "2", "3"],
        help="Cameras index",
        required=True,
    )
    parser.add_argument(
        "-dw",
        "--displaywidth",
        type=int,
        default=1280,
        help="Values for the width window",
        required=False,
    )
    parser.add_argument(
        "-dh",
        "--displayheight",
        type=int,
        default=720,
        help="Values for the height window",
        required=False,
    )
    parser.add_argument(
        "--debug", dest="debug", action="store_true", help="To do debug"
    )
    parser.add_argument(
        "--no-debug", dest="debug", action="store_false", help="To do debug"
    )
    parser.add_argument(
        "--gray",
        dest="gray_scale",
        action="store_true",
        help="Convert video to gray scale",
    )
    parser.add_argument(
        "--no-gray",
        dest="gray_scale",
        action="store_false",
        help="Convert video to gray scale",
    )
    parser.add_argument(
        "--enforce",
        dest="enforce_fps",
        action="store_true",
        help="Convert video to gray scale",
    )
    parser.add_argument(
        "--no-enforce",
        dest="enforce_fps",
        action="store_false",
        help="Convert video to gray scale",
    )

    # Parse the arguments
    args = parser.parse_args()

    if args.debug:
        print("Gray Scale in __Main__: ", args.gray_scale)
        print("Debug in __Main__: ", args.debug)
        print("Operating System in __Main__: ", args.windows)
        print("Camera Index in __Main__: ", args.indexcamera)

    main(
        args.fps,
        args.displaywidth,
        args.displayheight,
        args.debug,
        args.enforce_fps,
        args.gray_scale,
        args.windows,
        args.indexcamera,
    )

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"cv2 version:\", cv2.__version__)\n",
    "print(\"cv2 file   :\", cv2.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = cv2.getBuildInformation()\n",
    "print(\"\\n--- Resumen CUDA/Python ---\")\n",
    "for line in info.splitlines():\n",
    "    if \"NVIDIA CUDA:\" in line or \"cuDNN:\" in line or \"NVIDIA GPU arch:\" in line or line.strip().startswith(\"Python 3\"):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d74006",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCUDA devices:\", cv2.cuda.getCudaEnabledDeviceCount())\n",
    "if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "    for i in range(cv2.cuda.getCudaEnabledDeviceCount()):\n",
    "        device_info = cv2.cuda.printCudaDeviceInfo(i)\n",
    "        print(device_info)\n",
    "        #print(f\" Device {i}:\", cv2.cuda.DeviceInfo(i).name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ea87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import contextlib\n",
    "\n",
    "def get_device_name(index: int) -> str:\n",
    "    \"\"\"\n",
    "    Devuelve el nombre del dispositivo CUDA usando printShortCudaDeviceInfo.\n",
    "    \"\"\"\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf):\n",
    "        cv2.cuda.printShortCudaDeviceInfo(index)\n",
    "    salida = buf.getvalue().splitlines()\n",
    "    if not salida:\n",
    "        return f\"Device {index}\"\n",
    "    # Normalmente la primera l√≠nea es tipo: \"Device 0: NVIDIA GeForce RTX 4060\"\n",
    "    primera = salida[0].strip()\n",
    "    if \":\" in primera:\n",
    "        return primera.split(\":\", 1)[1].strip()\n",
    "    return primera\n",
    "\n",
    "def listar_dispositivos_cuda_detallado():\n",
    "    if not hasattr(cv2, \"cuda\"):\n",
    "        print(\"Esta versi√≥n de OpenCV no tiene el m√≥dulo cv2.cuda.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        num_devices = cv2.cuda.getCudaEnabledDeviceCount()\n",
    "    except Exception as e:\n",
    "        print(\"Error obteniendo el n√∫mero de dispositivos CUDA:\", e)\n",
    "        return\n",
    "\n",
    "    if num_devices == 0:\n",
    "        print(\"No se detectan GPUs CUDA o OpenCV no fue compilado con soporte CUDA.\")\n",
    "        return\n",
    "\n",
    "    print(f\"GPUs CUDA detectadas: {num_devices}\\n\")\n",
    "\n",
    "    for i in range(num_devices):\n",
    "        nombre = get_device_name(i)\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Dispositivo #{i} - {nombre}\")\n",
    "        print(\"=\" * 70)\n",
    "        cv2.cuda.printCudaDeviceInfo(i)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "listar_dispositivos_cuda_detallado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a25122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# 1. Listar dispositivos f√≠sicos\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDispositivos f√≠sicos visibles:\")\n",
    "for d in physical_devices:\n",
    "    print(\"  -\", d)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"\\nGPUs detectadas por TensorFlow:\", gpus)\n",
    "\n",
    "if not gpus:\n",
    "    print(\"\\n‚ùå TensorFlow NO ve GPUs. Est√° corriendo solo en CPU.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ TensorFlow ve al menos una GPU. Probando una operaci√≥n en la GPU...\")\n",
    "\n",
    "    # 2. Probar operaci√≥n sencilla en la GPU\n",
    "    try:\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            a = tf.random.normal((1000, 1000))\n",
    "            b = tf.random.normal((1000, 1000))\n",
    "            c = tf.matmul(a, b)\n",
    "\n",
    "        print(\"Resultado de matmul:\", c)\n",
    "        print(\"Dispositivo donde se ejecut√≥ c:\", c.device)\n",
    "\n",
    "        if \"GPU\" in c.device.upper():\n",
    "            print(\"\\nüéâ Todo bien: la operaci√≥n se ejecut√≥ en la GPU.\")\n",
    "        else:\n",
    "            print(\"\\n‚ö† La GPU existe, pero esta operaci√≥n parece ejecutarse en CPU.\")\n",
    "    except Exception as e:\n",
    "        print(\"\\n‚ö† Ocurri√≥ un error al intentar usar la GPU:\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursoetl_tf_ubuntu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
